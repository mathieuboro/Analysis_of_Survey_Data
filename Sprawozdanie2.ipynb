{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprawozdanie 2\n",
    "## Jakub Ciągło (275986), Mateusz Ćwiek (276011)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Importy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.stats.proportion import proportion_confint\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Część 1\n",
    "## Zadanie 1\n",
    "**Oszacowanie rozkładu opinii o szkoleniu – przedziały ufności dla wektora prawdopodobieństw** \n",
    "\n",
    "W zadaniu analizujemy odpowiedzi 200 pracowników, którzy oceniali szkolenie „Efektywna komunikacja w zespole”. Opinie zostały pogrupowane w pięć kategorii:  \n",
    "\n",
    "Na podstawie uzyskanych liczebności wyznaczamy przedziały ufności dla częstości odpowiedzi w każdej kategorii, traktując te częstości jako estymacje elementów wektora prawdopodobieństw dyskretnego rozkładu opinii.  \n",
    "\n",
    "Uwzględniamy dwa podejścia:  \n",
    "- Dokładne przedziały Cloppera-Pearsona oparte na rozkładzie beta,  \n",
    "- Przybliżone przedziały Wilsona (asymptotyczne).  \n",
    "\n",
    "Ze względu na pięć kategorii, poziom ufności dla każdej z nich został skorygowany metodą Bonferroniego (czyli poziom istotności $ \\alpha = 0.05 $ podzielono przez $5$).  \n",
    "\n",
    "Przedziały zostały wyznaczone niezależnie dla każdej kategorii, zakładając próbę o stałej liczebności $ n = 200 $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kategoria 1\n",
      "  Metoda Clopper-Pearson: (0.032, 0.130)\n",
      "  Metoda Wilson:          (0.036, 0.132)\n",
      "\n",
      "Kategoria 2\n",
      "  Metoda Clopper-Pearson: (0.042, 0.149)\n",
      "  Metoda Wilson:          (0.047, 0.150)\n",
      "\n",
      "Kategoria 3\n",
      "  Metoda Clopper-Pearson: (0.133, 0.282)\n",
      "  Metoda Wilson:          (0.137, 0.282)\n",
      "\n",
      "Kategoria 4\n",
      "  Metoda Clopper-Pearson: (0.407, 0.593)\n",
      "  Metoda Wilson:          (0.410, 0.590)\n",
      "\n",
      "Kategoria 5\n",
      "  Metoda Clopper-Pearson: (0.087, 0.220)\n",
      "  Metoda Wilson:          (0.092, 0.221)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def clopper_pearson_ci(successes, trials, alpha):\n",
    "    lower = stats.beta.ppf(alpha / 2, successes, trials - successes + 1)\n",
    "    upper = stats.beta.ppf(1 - alpha / 2, successes + 1, trials - successes)\n",
    "    return lower, upper\n",
    "\n",
    "def wyznacz_przedzialy_ufnosci(liczebnosci, alpha=0.05):\n",
    "    n = np.sum(liczebnosci)\n",
    "    kategorie = len(liczebnosci)\n",
    "    \n",
    "    adjusted_alpha = alpha / kategorie\n",
    "\n",
    "    przedzialy = []\n",
    "\n",
    "    for i, sukcesy in enumerate(liczebnosci):\n",
    "        cp_lower, cp_upper = clopper_pearson_ci(sukcesy, n, adjusted_alpha)\n",
    "\n",
    "        wilson_lower, wilson_upper = proportion_confint(sukcesy, n, alpha=adjusted_alpha, method='wilson')\n",
    "\n",
    "        przedzialy.append({\n",
    "            'kategoria': i + 1,\n",
    "            'dokladny': (cp_lower, cp_upper),\n",
    "            'asymptotyczny': (wilson_lower, wilson_upper)\n",
    "        })\n",
    "\n",
    "    return przedzialy\n",
    "\n",
    "liczebnosci = np.array([14, 17, 40, 100, 29])\n",
    "przedzialy = wyznacz_przedzialy_ufnosci(liczebnosci, alpha=0.05)\n",
    "\n",
    "for przedzial in przedzialy:\n",
    "    print(f\"Kategoria {przedzial['kategoria']}\")\n",
    "    print(f\"  Metoda Clopper-Pearson: ({przedzial['dokladny'][0]:.3f}, {przedzial['dokladny'][1]:.3f})\")\n",
    "    print(f\"  Metoda Wilson:          ({przedzial['asymptotyczny'][0]:.3f}, {przedzial['asymptotyczny'][1]:.3f})\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Zadanie 2\n",
    "**Poziomy krytyczne w testach dopasowania rozkładu – testy chi-kwadrat**\n",
    "\n",
    "Celem zadania było stworzenie funkcji obliczającej poziomy krytyczne (p-value) w dwóch klasycznych testach dopasowania rozkładu wielomianowego:\n",
    "\n",
    "- Test chi-kwadrat Pearsona,  \n",
    "- Test chi-kwadrat największej wiarygodności.\n",
    "\n",
    "Weryfikujemy hipotezę:\n",
    "$$\n",
    "H_0: \\mathbf{p} = \\mathbf{p}_0 \\quad \\text{przeciwko} \\quad H_1: \\mathbf{p} \\ne \\mathbf{p}_0\n",
    "$$\n",
    "na podstawie obserwacji $\\mathbf{x} = (x_1, \\dots, x_k)$ będącej realizacją zmiennej losowej z rozkładu wielomianowego o parametrach $n$ (łączna liczba prób) i $\\mathbf{p}$.\n",
    "\n",
    "W funkcji:\n",
    "\n",
    "- Obliczono wartość statystyki testowej Pearsona:  \n",
    "  $$\n",
    "  \\chi^2 = \\sum_{i=1}^k \\frac{(x_i - np_{0i})^2}{np_{0i}}\n",
    "  $$\n",
    "- Obliczono statystykę testu największej wiarygodności:  \n",
    "  $$\n",
    "  G^2 = 2 \\sum_{i=1}^k x_i \\log \\left( \\frac{x_i}{np_{0i}} \\right)\n",
    "  $$\n",
    "- Dla obu statystyk zwrócono wartość p-value obliczoną na podstawie rozkładu $\\chi^2$ z $k - 1$ stopniami swobody.  \n",
    "\n",
    "Funkcja przyjmuje dowolny rozkład teoretyczny $\\mathbf{p}_0$ i zestaw danych $\\mathbf{x}$, co pozwala łatwo porównywać dane empiryczne z dowolną hipotezą dotyczącą struktury rozkładu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poziomy_krytyczne(x, p_0):\n",
    "    k = len(p_0)\n",
    "    n = sum(x)\n",
    "    \n",
    "    pearson_stat = sum(((x[i] - n * p_0[i]) ** 2) / (n * p_0[i]) for i in range(k))\n",
    "\n",
    "    nw_stat = 2 * sum(x[i] * np.log(x[i] / (n * p_0[i])) for i in range(k) if x[i] > 0)\n",
    "    \n",
    "    p_value_pearson = 1 - stats.chi2.cdf(pearson_stat, k - 1)\n",
    "    p_value_nw = 1 - stats.chi2.cdf(nw_stat, k - 1)\n",
    "    \n",
    "    return float(p_value_pearson), float(p_value_nw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Zadanie 3\n",
    "\n",
    "**Test zgodności rozkładu odpowiedzi z rozkładem jednostajnym — Dział Produktowy**\n",
    "\n",
    "W tym zadaniu sprawdzono, czy rozkład odpowiedzi pracowników z Działu Produktowego na pytanie dotyczące wsparcia i materiałów szkoleniowych (PYT_1) można uznać za jednostajny, czyli czy każde z pięciu możliwych stanowisk (-2, -1, 0, 1, 2) było wybierane z jednakowym prawdopodobieństwem.\n",
    "\n",
    "Do weryfikacji hipotezy:\n",
    "$$\n",
    "H_0: \\text{rozkład odpowiedzi jest jednostajny (równe prawdopodobieństwa)} \\\\\n",
    "H_1: \\text{rozkład odpowiedzi nie jest jednostajny}\n",
    "$$\n",
    "wykorzystano dwie statystyki chi-kwadrat:\n",
    "\n",
    "- **Test Pearsona**,  \n",
    "- **Test największej wiarygodności**.\n",
    "\n",
    "Na podstawie otrzymanych wartości p (p-value) z obu testów oceniono, czy istnieją podstawy do odrzucenia hipotezy zerowej na poziomie istotności $\\alpha = 0.05$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczności odpowiedzi: [9, 10, 17, 51, 11]\n",
      "Statystyka chi² Pearsona (dla poziomu istotności α = 0.05):\n",
      "  p-wartość = 2.757793993168889e-13\n",
      "  → Odrzucamy hipotezę zerową (rozkład nie jest równomierny)\n",
      "\n",
      "Statystyka chi² największej wiarygodności (dla poziomu istotności α = 0.05):\n",
      "  p-wartość = 1.0701994845874196e-10\n",
      "  → Odrzucamy hipotezę zerową (rozkład nie jest równomierny)\n"
     ]
    }
   ],
   "source": [
    "alfa = 0.05\n",
    "df = pd.read_csv('ankieta.csv', encoding='Latin2', sep=';')\n",
    "\n",
    "df_produktowy = df[df['DZIAŁ'] == 'PD']\n",
    "\n",
    "odpowiedzi = [-2, -1, 0, 1, 2]\n",
    "n = df_produktowy['PYT_1'].value_counts().reindex(odpowiedzi, fill_value=0).tolist()\n",
    "print('Liczności odpowiedzi:', n)\n",
    "\n",
    "p_0 = [1/len(n) for _ in range(len(n))] # w hipotezie zakładamy, że prawdopodobieństwa są równe\n",
    "p_value_pearson, p_value_nw = poziomy_krytyczne(n,p_0)\n",
    "\n",
    "p_value_pearson, p_value_nw = poziomy_krytyczne(n, p_0)\n",
    "\n",
    "print(f'Statystyka chi² Pearsona (dla poziomu istotności α = {alfa}):')\n",
    "print(f'  p-wartość = {p_value_pearson}')\n",
    "if p_value_pearson > alfa:\n",
    "    print('  → Brak podstaw do odrzucenia hipotezy zerowej (rozkład może być równomierny)')\n",
    "else:\n",
    "    print('  → Odrzucamy hipotezę zerową (rozkład nie jest równomierny)')\n",
    "\n",
    "print(f'\\nStatystyka chi² największej wiarygodności (dla poziomu istotności α = {alfa}):')\n",
    "print(f'  p-wartość = {p_value_nw}')\n",
    "if p_value_nw > alfa:\n",
    "    print('  → Brak podstaw do odrzucenia hipotezy zerowej (rozkład może być równomierny)')\n",
    "else:\n",
    "    print('  → Odrzucamy hipotezę zerową (rozkład nie jest równomierny)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Zadanie 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CZY_KIER  Nie  Tak\n",
      "PŁEĆ              \n",
      "K          63    8\n",
      "M         110   19\n",
      "Wynik testu Fishera:\n",
      "  odds ratio: 1.3602272727272726\n",
      "  p-value: 0.6659028889666552\n",
      "Brak podstaw do odrzucenia H0 -> nie ma dowodów na zależność.\n"
     ]
    }
   ],
   "source": [
    "# 2. Budowanie tabeli 2×2\n",
    "contingency_table = pd.crosstab(df['PŁEĆ'], df['CZY_KIER'])\n",
    "print(contingency_table)\n",
    "\n",
    "oddsratio, p_value = stats.fisher_exact(contingency_table)\n",
    "\n",
    "print(\"Wynik testu Fishera:\")\n",
    "print(f\"  odds ratio: {oddsratio}\")\n",
    "print(f\"  p-value: {p_value}\")\n",
    "\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Odrzucamy hipotezę zerową -> zmienne 'PŁEĆ' i 'CZY_KIER' są zależne.\")\n",
    "else:\n",
    "    print(\"Brak podstaw do odrzucenia H0 -> nie ma dowodów na zależność.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeśli p‑value < 0.05, odrzucamy hipotezę o niezależności, co oznacza, że istnieje istotna statystycznie różnica w prawdopodobieństwie bycia na stanowisku kierowniczym między kobietami a mężczyznami.\n",
    "\n",
    "Jeśli p‑value ≥ 0.05 - tak jak w wyniku zadania, mamy brak podstaw do odrzucenia hipotezy zerowej, czyli test Fishera ($p = 0.6659$) nie wykazał istotnej różnicy między kobietami i mężczyznami w udziale stanowisk kierowniczych, co oznacza, że prawdopodobieństwo pełnienia funkcji kierowniczej jest w obu grupach statystycznie zbliżone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Zadanie 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"R_HOME\"] = r\"C:\\Program Files\\R\\R-4.5.0\"\n",
    "os.environ[\"PATH\"] += r\";C:\\Program Files\\R\\R-4.5.0\\bin\\x64\"\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects.packages import importr\n",
    "stats = importr(\"stats\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a) CZY_KIER × WIEK_KAT   p = 0.7823  → brak podstaw\n",
      "b) CZY_KIER × STAŻ       p = 0.0001  → ODRZUCAMY H₀\n",
      "c) PYT_2 × CZY_KIER   p = 0.0443  → ODRZUCAMY H₀\n",
      "d) PYT_2 × STAŻ       p = 0.0107  → ODRZUCAMY H₀\n",
      "e) PYT_2 × PŁEĆ       p = 0.4758  → brak podstaw\n",
      "f) PYT_2 × WIEK_KAT   p = 0.3194  → brak podstaw\n",
      "\n",
      "--- PYT_2 zastąpione przez CZY_ZADOW ---\n",
      "c′) CZY_ZADOW × CZY_KIER   p = 0.8377  → brak podstaw\n",
      "d′) CZY_ZADOW × STAŻ       p = 0.4097  → brak podstaw\n",
      "e′) CZY_ZADOW × PŁEĆ       p = 0.6589  → brak podstaw\n",
      "f′) CZY_ZADOW × WIEK_KAT   p = 0.3275  → brak podstaw\n"
     ]
    }
   ],
   "source": [
    "from rpy2.robjects import pandas2ri; pandas2ri.activate()\n",
    "\n",
    "df[\"CZY_ZADOW\"] = df[\"PYT_2\"].replace({\n",
    "    -2: \"niezadowolony\",\n",
    "    -1: \"niezadowolony\",\n",
    "     1: \"zadowolony\",\n",
    "     2: \"zadowolony\"\n",
    "})\n",
    "\n",
    "df[\"WIEK_KAT\"] = pd.cut(\n",
    "        df[\"WIEK\"],\n",
    "        bins=[0, 35, 45, 55, float(\"inf\")],\n",
    "        labels=[\"do 35 lat\", \"36‑45 lat\", \"46‑55 lat\", \"powyżej 55 lat\"])\n",
    "\n",
    "\n",
    "def fisher_fh(tab, simulate=False, B=50000, workspace=300000):\n",
    "    r_tab = pandas2ri.py2rpy(tab)\n",
    "    res   = stats.fisher_test(\n",
    "               r_tab,\n",
    "               simulate_p_value = simulate,\n",
    "               B        = B if simulate else 0,\n",
    "               workspace = workspace if not simulate else None\n",
    "           )\n",
    "    return dict(res.items())[\"p.value\"][0]\n",
    "\n",
    "\n",
    "hipotezy = [\n",
    "    (\"CZY_KIER\", \"WIEK_KAT\",  \"a\"),\n",
    "    (\"CZY_KIER\", \"STAŻ\",    \"b\"),\n",
    "    (\"PYT_2\",    \"CZY_KIER\",  \"c\"),\n",
    "    (\"PYT_2\",    \"STAŻ\",    \"d\"),\n",
    "    (\"PYT_2\",    \"PŁEĆ\",      \"e\"),\n",
    "    (\"PYT_2\",    \"WIEK_KAT\",  \"f\"),\n",
    "]\n",
    "\n",
    "for x, y, et in hipotezy:\n",
    "    tab = pd.crosstab(df[x], df[y])\n",
    "    p   = fisher_fh(tab, simulate = tab.size > 25)\n",
    "    decyzja = \"ODRZUCAMY H₀\" if p < 0.05 else \"brak podstaw\"\n",
    "    print(f\"{et}) {x} × {y:<9}  p = {p:6.4f}  → {decyzja}\")\n",
    "\n",
    "print(\"\\n--- PYT_2 zastąpione przez CZY_ZADOW ---\")\n",
    "for x, y, et in [\n",
    "        (\"CZY_ZADOW\", \"CZY_KIER\", \"c′\"),\n",
    "        (\"CZY_ZADOW\", \"STAŻ\",   \"d′\"),\n",
    "        (\"CZY_ZADOW\", \"PŁEĆ\",     \"e′\"),\n",
    "        (\"CZY_ZADOW\", \"WIEK_KAT\", \"f′\")]:\n",
    "    tab = pd.crosstab(df[x], df[y])\n",
    "    p   = fisher_fh(tab, simulate = tab.size > 25)\n",
    "    decyzja = \"ODRZUCAMY H₀\" if p < 0.05 else \"brak podstaw\"\n",
    "    print(f\"{et}) {x} × {y:<9}  p = {p:6.4f}  → {decyzja}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W świetle przeprowadzonych testów okazuje się, że zajmowanie stanowiska kierowniczego nie ma związku z wiekiem ($p = 0.7823$), natomiast jest silnie związane ze stażem pracy ($p = 0,0001$). Gdy używamy oryginalnej, wielostopniowej skali satysfakcji (PYT_2), to poziom zadowolenia okazuje się zależeć zarówno od pełnienia funkcji kierowniczej ($p = 0.0443$), jak i od stażu pracy ($p = 0.0107$), podczas gdy płeć i wiek nie wykazują wpływu. Jednak po zredukowaniu skali do dwuwartościowej zmiennej CZY_ZADOW wszystkie testy c′–f′ tracą istotność (najniższe $p = 0.3275$), co sugeruje, że agregacja odpowiedzi z tytułu uproszczenia skali wygładza różnice i „maskuje” wcześniej obserwowane zależności."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
