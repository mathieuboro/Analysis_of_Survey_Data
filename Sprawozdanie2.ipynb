{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprawozdanie 2\n",
    "## Jakub Ciągło (275986), Mateusz Ćwiek (276011)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Importy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.stats.proportion import proportion_confint\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Część 1\n",
    "## Zadanie 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kategoria 1\n",
      "  Metoda Clopper-Pearson: (0.032, 0.130)\n",
      "  Metoda Wilson:          (0.036, 0.132)\n",
      "\n",
      "Kategoria 2\n",
      "  Metoda Clopper-Pearson: (0.042, 0.149)\n",
      "  Metoda Wilson:          (0.047, 0.150)\n",
      "\n",
      "Kategoria 3\n",
      "  Metoda Clopper-Pearson: (0.133, 0.282)\n",
      "  Metoda Wilson:          (0.137, 0.282)\n",
      "\n",
      "Kategoria 4\n",
      "  Metoda Clopper-Pearson: (0.407, 0.593)\n",
      "  Metoda Wilson:          (0.410, 0.590)\n",
      "\n",
      "Kategoria 5\n",
      "  Metoda Clopper-Pearson: (0.087, 0.220)\n",
      "  Metoda Wilson:          (0.092, 0.221)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def clopper_pearson_ci(successes, trials, alpha):\n",
    "    lower = stats.beta.ppf(alpha / 2, successes, trials - successes + 1)\n",
    "    upper = stats.beta.ppf(1 - alpha / 2, successes + 1, trials - successes)\n",
    "    return lower, upper\n",
    "\n",
    "def wyznacz_przedzialy_ufnosci(liczebnosci, alpha=0.05):\n",
    "    n = np.sum(liczebnosci)\n",
    "    kategorie = len(liczebnosci)\n",
    "    \n",
    "    adjusted_alpha = alpha / kategorie\n",
    "\n",
    "    przedzialy = []\n",
    "\n",
    "    for i, sukcesy in enumerate(liczebnosci):\n",
    "        cp_lower, cp_upper = clopper_pearson_ci(sukcesy, n, adjusted_alpha)\n",
    "\n",
    "        wilson_lower, wilson_upper = proportion_confint(sukcesy, n, alpha=adjusted_alpha, method='wilson')\n",
    "\n",
    "        przedzialy.append({\n",
    "            'kategoria': i + 1,\n",
    "            'dokladny': (cp_lower, cp_upper),\n",
    "            'asymptotyczny': (wilson_lower, wilson_upper)\n",
    "        })\n",
    "\n",
    "    return przedzialy\n",
    "\n",
    "liczebnosci = np.array([14, 17, 40, 100, 29])\n",
    "przedzialy = wyznacz_przedzialy_ufnosci(liczebnosci, alpha=0.05)\n",
    "\n",
    "for przedzial in przedzialy:\n",
    "    print(f\"Kategoria {przedzial['kategoria']}\")\n",
    "    print(f\"  Metoda Clopper-Pearson: ({przedzial['dokladny'][0]:.3f}, {przedzial['dokladny'][1]:.3f})\")\n",
    "    print(f\"  Metoda Wilson:          ({przedzial['asymptotyczny'][0]:.3f}, {przedzial['asymptotyczny'][1]:.3f})\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Zadanie 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0, 1.0)\n"
     ]
    }
   ],
   "source": [
    "def poziomy_krytyczne(x, p_0):\n",
    "    k = len(p_0)\n",
    "    n = sum(x)\n",
    "    \n",
    "    pearson_stat = sum(((x[i] - n * p_0[i]) ** 2) / (n * p_0[i]) for i in range(k))\n",
    "\n",
    "    nw_stat = 2 * sum(x[i] * np.log(x[i] / (n * p_0[i])) for i in range(k) if x[i] > 0)\n",
    "    \n",
    "    p_value_pearson = 1 - stats.chi2.cdf(pearson_stat, k - 1)\n",
    "    p_value_nw = 1 - stats.chi2.cdf(nw_stat, k - 1)\n",
    "    \n",
    "    return float(p_value_pearson), float(p_value_nw)\n",
    "\n",
    "x = [20, 20, 20, 20]\n",
    "p = [0.25, 0.25, 0.25, 0.25]\n",
    "print(poziomy_krytyczne(x, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Zadanie 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczności odpowiedzi: [9, 10, 17, 51, 11]\n",
      "Statystyka chi² Pearsona (dla poziomu istotności α = 0.05):\n",
      "  p-wartość = 2.757793993168889e-13\n",
      "  → Odrzucamy hipotezę zerową (rozkład nie jest równomierny)\n",
      "\n",
      "Statystyka chi² największej wiarygodności (dla poziomu istotności α = 0.05):\n",
      "  p-wartość = 1.0701994845874196e-10\n",
      "  → Odrzucamy hipotezę zerową (rozkład nie jest równomierny)\n"
     ]
    }
   ],
   "source": [
    "alfa = 0.05\n",
    "df = pd.read_csv('ankieta.csv', encoding='Latin2', sep=';')\n",
    "\n",
    "df_produktowy = df[df['DZIAŁ'] == 'PD']\n",
    "\n",
    "odpowiedzi = [-2, -1, 0, 1, 2]\n",
    "n = df_produktowy['PYT_1'].value_counts().reindex(odpowiedzi, fill_value=0).tolist()\n",
    "print('Liczności odpowiedzi:', n)\n",
    "\n",
    "p_0 = [1/len(n) for _ in range(len(n))] # w hipotezie zakładamy, że prawdopodobieństwa są równe\n",
    "p_value_pearson, p_value_nw = poziomy_krytyczne(n,p_0)\n",
    "\n",
    "p_value_pearson, p_value_nw = poziomy_krytyczne(n, p_0)\n",
    "\n",
    "print(f'Statystyka chi² Pearsona (dla poziomu istotności α = {alfa}):')\n",
    "print(f'  p-wartość = {p_value_pearson}')\n",
    "if p_value_pearson > alfa:\n",
    "    print('  → Brak podstaw do odrzucenia hipotezy zerowej (rozkład może być równomierny)')\n",
    "else:\n",
    "    print('  → Odrzucamy hipotezę zerową (rozkład nie jest równomierny)')\n",
    "\n",
    "print(f'\\nStatystyka chi² największej wiarygodności (dla poziomu istotności α = {alfa}):')\n",
    "print(f'  p-wartość = {p_value_nw}')\n",
    "if p_value_nw > alfa:\n",
    "    print('  → Brak podstaw do odrzucenia hipotezy zerowej (rozkład może być równomierny)')\n",
    "else:\n",
    "    print('  → Odrzucamy hipotezę zerową (rozkład nie jest równomierny)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Zadanie 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CZY_KIER  Nie  Tak\n",
      "PŁEĆ              \n",
      "K          63    8\n",
      "M         110   19\n",
      "Wynik testu Fishera:\n",
      "  odds ratio: 1.3602272727272726\n",
      "  p-value: 0.6659028889666552\n",
      "Brak podstaw do odrzucenia H0 -> nie ma dowodów na zależność.\n"
     ]
    }
   ],
   "source": [
    "# 2. Budowanie tabeli 2×2\n",
    "# Wartości w kolumnach: 'PŁEĆ' (K/M), 'CZY_KIER' (Tak/Nie)\n",
    "contingency_table = pd.crosstab(df['PŁEĆ'], df['CZY_KIER'])\n",
    "print(contingency_table)\n",
    "\n",
    "# 3. Test Fishera\n",
    "oddsratio, p_value = stats.fisher_exact(contingency_table)\n",
    "\n",
    "print(\"Wynik testu Fishera:\")\n",
    "print(f\"  odds ratio: {oddsratio}\")\n",
    "print(f\"  p-value: {p_value}\")\n",
    "\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Odrzucamy hipotezę zerową -> zmienne 'PŁEĆ' i 'CZY_KIER' są zależne.\")\n",
    "else:\n",
    "    print(\"Brak podstaw do odrzucenia H0 -> nie ma dowodów na zależność.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeśli p‑value < 0.05, odrzucamy hipotezę o niezależności, co oznacza, że istnieje istotna statystycznie różnica w prawdopodobieństwie bycia na stanowisku kierowniczym między kobietami a mężczyznami.\n",
    "\n",
    "Jeśli p‑value ≥ 0.05 - tak jak w wyniku zadania, mamy brak podstaw do odrzucenia hipotezy zerowej, czyli nie wykryto istotnej różnicy – wtedy możemy uznać, że dane nie przeczą temu, iż prawdopodobieństwo kierowniczego stanowiska u kobiet jest podobne jak u mężczyzn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Zadanie 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To jest raczej źle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from math import comb, log\n",
    "import random\n",
    "\n",
    "def freeman_halton_test(observed, n_permutations=100_000, seed=42):\n",
    "    \"\"\"\n",
    "    Uproszczona implementacja testu Freedmana-Haltona dla tabeli m×n.\n",
    "    Parametry:\n",
    "      observed: 2D array-like (m×n), tabela kontyngencji\n",
    "      n_permutations: liczba permutacji w symulacji\n",
    "      seed: seed generatora liczb losowych (dla powtarzalności)\n",
    "\n",
    "    Zwraca:\n",
    "      stat_observed: statystyka z oryginalnej tabeli\n",
    "      p_value: p-wartość obliczona permutacyjnie\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    observed = np.array(observed, dtype=int)\n",
    "    row_sums = observed.sum(axis=1)\n",
    "    col_sums = observed.sum(axis=0)\n",
    "    total = observed.sum()\n",
    "\n",
    "    # Funkcja licząca tzw. 'pseudoprawdopodobieństwo' (analogiczna do Fishera) \n",
    "    # P(table | row_sums, col_sums) ~ (prod factorial) / factorial(total)\n",
    "    # ale wystarczy porównać log-prob\n",
    "    def log_multinomial(table):\n",
    "        # log(P) ~ sum(logfactorial(table_ij)) minus logfactorial(row_sums, col_sums, total)\n",
    "        # wystarczy część licznika, bo mianownik jest stały przy fixed margins\n",
    "        # W praktyce raczej liczymy sum(logfactorial(x_ij)), itp.\n",
    "\n",
    "        # Lepsza implementacja:\n",
    "        val = 0\n",
    "        for i in range(table.shape[0]):\n",
    "            for j in range(table.shape[1]):\n",
    "                x = table[i, j]\n",
    "                # logfactorial(x)\n",
    "                val += math.lgamma(x + 1)\n",
    "        return val\n",
    "\n",
    "    # Oryginalna \"statystyka\" (log-likelihood macierzy)\n",
    "    stat_observed = log_multinomial(observed)\n",
    "\n",
    "    # Funkcja do budowy losowej tabeli z takimi samymi sumami brzegowymi\n",
    "    # (row_sums i col_sums), np. metodą pogram-lan lub biprocesu\n",
    "    # Tu używamy prostej metody iterative proportional fitting albo\n",
    "    # sample z fisher FreedmanHalton. Poniżej skrócona, orientacyjna.\n",
    "    def random_table(row_sums, col_sums):\n",
    "        # Prosty algorytm step-by-step (nieoptymalny), wrzucanie komórek\n",
    "        # Minimalny prymitywny approach:\n",
    "        m = len(row_sums)\n",
    "        n = len(col_sums)\n",
    "        table = np.zeros((m, n), dtype=int)\n",
    "        rows_left = row_sums.copy()\n",
    "        cols_left = col_sums.copy()\n",
    "\n",
    "        for i in range(m-1):\n",
    "            for j in range(n-1):\n",
    "                # Maks. co możemy wstawić to min(rows_left[i], cols_left[j])\n",
    "                x = np.random.randint(0, min(rows_left[i], cols_left[j]) + 1)\n",
    "                table[i,j] = x\n",
    "                rows_left[i] -= x\n",
    "                cols_left[j] -= x\n",
    "            # Ostatnia kolumna w wierszu i\n",
    "            table[i, n-1] = rows_left[i]\n",
    "            cols_left[n-1] -= rows_left[i]\n",
    "            rows_left[i] = 0\n",
    "\n",
    "        # Ostatni wiersz\n",
    "        for j in range(n-1):\n",
    "            table[m-1, j] = cols_left[j]\n",
    "            rows_left[m-1] -= cols_left[j]\n",
    "            cols_left[j] = 0\n",
    "        table[m-1, n-1] = rows_left[m-1]\n",
    "        return table\n",
    "\n",
    "    # Liczymy ile permutacji daje statystykę <= stat_observed (bo test dwustronny analogicznie).\n",
    "    count_better = 0\n",
    "    for _ in range(n_permutations):\n",
    "        rand_tab = random_table(row_sums, col_sums)\n",
    "        stat_rand = log_multinomial(rand_tab)\n",
    "        if stat_rand <= stat_observed:\n",
    "            count_better += 1\n",
    "\n",
    "    p_value = count_better / n_permutations\n",
    "    return stat_observed, p_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['WIEK_KAT'] = pd.cut(df['WIEK'], \n",
    "                        bins=[0, 35, 45, 55, float('inf')], \n",
    "                        labels=['do 35 lat', '36-45 lat', '46-55 lat', 'powyżej 55 lat'],\n",
    "                        right=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "math domain error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.05\u001b[39m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# a) CZY_KIER vs. WIEK_KAT\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m pval_a, dec_a \u001b[38;5;241m=\u001b[39m \u001b[43mtest_freeman_halton_independence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCZY_KIER\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWIEK_KAT\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(a) Test Freedmana-Haltona:\u001b[39m\u001b[38;5;124m\"\u001b[39m, pval_a, dec_a)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# b) CZY_KIER vs. STAZ\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[10], line 12\u001b[0m, in \u001b[0;36mtest_freeman_halton_independence\u001b[1;34m(df, var1, var2, alpha, n_permutations)\u001b[0m\n\u001b[0;32m      9\u001b[0m observed \u001b[38;5;241m=\u001b[39m contingency\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Wywołanie testu Freedmana-Haltona (kod poglądowy)\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m stat_obs, p_value \u001b[38;5;241m=\u001b[39m \u001b[43mfreeman_halton_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_permutations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_permutations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p_value \u001b[38;5;241m<\u001b[39m alpha:\n\u001b[0;32m     15\u001b[0m     decision \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOdrzucamy H0: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvar1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m i \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvar2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m są zależne.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[1;32mIn[7], line 81\u001b[0m, in \u001b[0;36mfreeman_halton_test\u001b[1;34m(observed, n_permutations, seed)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_permutations):\n\u001b[0;32m     80\u001b[0m     rand_tab \u001b[38;5;241m=\u001b[39m random_table(row_sums, col_sums)\n\u001b[1;32m---> 81\u001b[0m     stat_rand \u001b[38;5;241m=\u001b[39m \u001b[43mlog_multinomial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrand_tab\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stat_rand \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m stat_observed:\n\u001b[0;32m     83\u001b[0m         count_better \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[1;32mIn[7], line 38\u001b[0m, in \u001b[0;36mfreeman_halton_test.<locals>.log_multinomial\u001b[1;34m(table)\u001b[0m\n\u001b[0;32m     36\u001b[0m         x \u001b[38;5;241m=\u001b[39m table[i, j]\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;66;03m# logfactorial(x)\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m         val \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlgamma\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m val\n",
      "\u001b[1;31mValueError\u001b[0m: math domain error"
     ]
    }
   ],
   "source": [
    "def test_freeman_halton_independence(df, var1, var2, alpha=0.05, n_permutations=2000):\n",
    "    \"\"\"\n",
    "    Weryfikuje hipotezę niezależności var1 i var2 w DataFrame df\n",
    "    na poziomie istotności alpha, używając testu Freedmana-Haltona.\n",
    "    Zwraca p_value i komunikat -> 'Odrzucamy H0' lub 'Brak podstaw do odrzucenia H0'.\n",
    "    \"\"\"\n",
    "    # Budujemy tabelę kontyngencji\n",
    "    contingency = pd.crosstab(df[var1], df[var2])\n",
    "    observed = contingency.values\n",
    "    \n",
    "    # Wywołanie testu Freedmana-Haltona (kod poglądowy)\n",
    "    stat_obs, p_value = freeman_halton_test(observed, n_permutations=n_permutations)\n",
    "    \n",
    "    if p_value < alpha:\n",
    "        decision = f\"Odrzucamy H0: {var1} i {var2} są zależne.\"\n",
    "    else:\n",
    "        decision = f\"Brak podstaw do odrzucenia H0: nie wykryto zależności między {var1} i {var2}.\"\n",
    "    return p_value, decision\n",
    "\n",
    "# --- ZASTOSOWANIE ---\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "# a) CZY_KIER vs. WIEK_KAT\n",
    "pval_a, dec_a = test_freeman_halton_independence(df, 'CZY_KIER', 'WIEK_KAT', alpha)\n",
    "print(\"(a) Test Freedmana-Haltona:\", pval_a, dec_a)\n",
    "\n",
    "# b) CZY_KIER vs. STAZ\n",
    "pval_b, dec_b = test_freeman_halton_independence(df, 'CZY_KIER', 'STAZ', alpha)\n",
    "print(\"(b) Test Freedmana-Haltona:\", pval_b, dec_b)\n",
    "\n",
    "# c) PYT_2 vs. CZY_KIER\n",
    "pval_c, dec_c = test_freeman_halton_independence(df, 'PYT_2', 'CZY_KIER', alpha)\n",
    "print(\"(c) Test Freedmana-Haltona:\", pval_c, dec_c)\n",
    "\n",
    "# d) PYT_2 vs. STAZ\n",
    "pval_d, dec_d = test_freeman_halton_independence(df, 'PYT_2', 'STAZ', alpha)\n",
    "print(\"(d) Test Freedmana-Haltona:\", pval_d, dec_d)\n",
    "\n",
    "# e) PYT_2 vs. PŁEĆ\n",
    "pval_e, dec_e = test_freeman_halton_independence(df, 'PYT_2', 'PŁEĆ', alpha)\n",
    "print(\"(e) Test Freedmana-Haltona:\", pval_e, dec_e)\n",
    "\n",
    "# f) PYT_2 vs. WIEK_KAT\n",
    "pval_f, dec_f = test_freeman_halton_independence(df, 'PYT_2', 'WIEK_KAT', alpha)\n",
    "print(\"(f) Test Freedmana-Haltona:\", pval_f, dec_f)\n",
    "\n",
    "# Następnie powtarzamy c), d), e), f), zastępując PYT_2 przez CZY_ZADOW\n",
    "# Najpierw w df definiujemy:\n",
    "# df['CZY_ZADOW'] = df['PYT_2'].replace({\n",
    "#     -2: 'niezadowolony', -1: 'niezadowolony', 1: 'zadowolony', 2: 'zadowolony'\n",
    "# })\n",
    "\n",
    "# c') CZY_ZADOW vs. CZY_KIER\n",
    "pval_cz_c, dec_cz_c = test_freeman_halton_independence(df, 'CZY_ZADOW', 'CZY_KIER', alpha)\n",
    "print(\"(c') Freedman-Halton z CZY_ZADOW:\", pval_cz_c, dec_cz_c)\n",
    "\n",
    "# d') CZY_ZADOW vs. STAZ\n",
    "pval_cz_d, dec_cz_d = test_freeman_halton_independence(df, 'CZY_ZADOW', 'STAZ', alpha)\n",
    "print(\"(d') Freedman-Halton z CZY_ZADOW:\", pval_cz_d, dec_cz_d)\n",
    "\n",
    "# e') CZY_ZADOW vs. PŁEĆ\n",
    "pval_cz_e, dec_cz_e = test_freeman_halton_independence(df, 'CZY_ZADOW', 'PŁEĆ', alpha)\n",
    "print(\"(e') Freedman-Halton z CZY_ZADOW:\", pval_cz_e, dec_cz_e)\n",
    "\n",
    "# f') CZY_ZADOW vs. WIEK_KAT\n",
    "pval_cz_f, dec_cz_f = test_freeman_halton_independence(df, 'CZY_ZADOW', 'WIEK_KAT', alpha)\n",
    "print(\"(f') Freedman-Halton z CZY_ZADOW:\", pval_cz_f, dec_cz_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "próba nr 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import comb\n",
    "import itertools\n",
    "\n",
    "def hypergeom_pmf(table):\n",
    "    \"\"\"\n",
    "    Oblicza dokładną wartość funkcji masy prawdopodobieństwa (PMF)\n",
    "    dla podanej tablicy kontyngencji (2D) w oparciu o rozkład hipergeometryczny wielowymiarowy.\n",
    "    \n",
    "    table: pd.DataFrame lub np.ndarray – macierz R×C.\n",
    "    Zakładamy, że sumy wierszy i kolumn są z góry 'zadane'.\n",
    "    \"\"\"\n",
    "    # table musi być np.ndarray dla uproszczenia operacji\n",
    "    table = np.array(table, dtype=int)\n",
    "    row_sums = table.sum(axis=1)\n",
    "    col_sums = table.sum(axis=0)\n",
    "    grand_total = table.sum()\n",
    "    \n",
    "    # Licznik - iloczyn silni wartości w komórkach\n",
    "    # W testach Fishera dla 2x2 jest analogiczny wzór, tu – uogólnienie\n",
    "    # Prawdopodobieństwo ~ (prod( row_sums! ) * prod( col_sums! )) / grand_total! \n",
    "    # ale z uwzględnieniem części poświęconej wartościom w komórkach.\n",
    "    \n",
    "    # Można zapisać to za pomocą:\n",
    "    # P(X = table) = ( prod_{i,j} (comb(row_sums[i], table[i,j]) ) ) / comb(grand_total, col_sums[0], col_sums[1], ...)\n",
    "    # przy zachowanych sumach brzegowych.\n",
    "\n",
    "    # Metoda 1 (wersja \"product of combs\"):\n",
    "    # - Licznik: iloczyn comb(row_sum_i, table[i,j]) dla każdej komórki w wierszu i\n",
    "    # - Mianownik: comb(grand_total, col_sums[0], col_sums[1], ...)\n",
    "\n",
    "    numerator = 1\n",
    "    for i in range(table.shape[0]):\n",
    "        # Rozkład w i-tym wierszu\n",
    "        row_total = row_sums[i]\n",
    "        for j in range(table.shape[1]):\n",
    "            numerator *= comb(row_total, table[i,j])\n",
    "            row_total -= table[i,j]\n",
    "\n",
    "    # Mianownik - wielowymiarowy współczynnik ( multinomial ), np. comb(grand_total, c1) * comb(grand_total-c1, c2) ...\n",
    "    # co można zapisać jako:\n",
    "    # comb(grand_total, col_sums[0]) * comb(grand_total-col_sums[0], col_sums[1]) * ... itd.\n",
    "    # lub jako:\n",
    "    # denominator = math.prod( comb( sum_{k=j to end} col_sums[k], col_sums[j] ) ) ...\n",
    "    # Ewentualnie można posłużyć się:\n",
    "    #   multinomial = grand_total! / ( col_sums[0]! col_sums[1]! ... col_sums[C-1]! )\n",
    "    # ale wtedy w liczniku też trzeba by było liczyć przez silnie.\n",
    "    # Dla spójności z powyższym liczymy iteracyjnie:\n",
    "    \n",
    "    denominator = 1\n",
    "    tmp = grand_total\n",
    "    for csum in col_sums:\n",
    "        denominator *= comb(tmp, csum)\n",
    "        tmp -= csum\n",
    "    \n",
    "    return numerator / denominator\n",
    "\n",
    "def fisher_freeman_halton(table, method=\"exact\", n_iter=10000, random_state=42):\n",
    "    \"\"\"\n",
    "    Test Freemana–Haltona oparty o enumerację (dokładny) lub metodę Monte Carlo\n",
    "    dla tabeli R×C. Zwraca p-value.\n",
    "    \n",
    "    - table: pd.DataFrame lub np.ndarray z nieujemnymi całkowitymi (liczności)\n",
    "    - method: 'exact' lub 'montecarlo'\n",
    "    - n_iter: liczba permutacji w metodzie Monte Carlo\n",
    "    - random_state: do odtworzenia losowości\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # Jeśli to DataFrame, konwertujemy\n",
    "    if isinstance(table, pd.DataFrame):\n",
    "        table = table.values\n",
    "    \n",
    "    row_sums = table.sum(axis=1)\n",
    "    col_sums = table.sum(axis=0)\n",
    "    grand_total = table.sum()\n",
    "    \n",
    "    # Policzymy p_obs = wartość pmf(tabela zaobserwowana)\n",
    "    p_obs = hypergeom_pmf(table)\n",
    "    \n",
    "    # 1) Metoda EXACT (enumeracja) – UWAGA: może być niewykonalna przy zbyt dużych tabelach\n",
    "    if method == \"exact\":\n",
    "        # Tworzymy wszystkie możliwe tabele z takimi samymi sumami brzegowymi:\n",
    "        # to wymaga zagnieżdżonej enumeracji, co bywa ekspresowo rosnące z rozmiarem.\n",
    "        # Dla małych tabel 2x2, 2x3, 3x3 i małych sum – można próbować.\n",
    "        all_tables = []\n",
    "        \n",
    "        # Prosty (choć może nieoptymalny) sposób: \n",
    "        # iterujemy po wszystkich możliwych kombinacjach wartości w wierszach, \n",
    "        # które sumują się do row_sums[i], ale też muszą się zgadzać z col_sums.\n",
    "        # W praktyce – dość skomplikowane do napisania ręcznie dla ogólnej R×C.\n",
    "        # Dla uproszczenia zostawiamy taki zarys:\n",
    "        \n",
    "        # Uwaga: implementacja pełnej enumeracji R×C \"od zera\" jest dość długa,\n",
    "        # poniżej tylko szkic, dlatego w praktyce częściej wybiera się Monte Carlo\n",
    "        # lub pakiety gotowe w R / zewn. biblioteki.\n",
    "        \n",
    "        # PRZYKŁADOWY, niekompletny ZARYS:\n",
    "        raise NotImplementedError(\"Metoda 'exact' (pełna enumeracja) jest zarysowana, \"\n",
    "                                  \"ale w tej wersji niezaimplementowana. \"\n",
    "                                  \"Skorzystaj z 'montecarlo' dla większych tabel.\")\n",
    "    \n",
    "    # 2) Metoda MONTE CARLO\n",
    "    # losujemy n_iter permutacji „zgodnych brzegowo” i zliczamy, ile ma p <= p_obs\n",
    "    count_le = 0\n",
    "    \n",
    "    for _ in range(n_iter):\n",
    "        # Losujemy tablicę o tych samych sumach brzegowych,\n",
    "        # np. metodą iterative proportional fitting lub prostszą losową:\n",
    "        # - najprostszy (choć niezbyt efektywny) sposób to wielokrotnie tasować wiersze,\n",
    "        #   sprawdzać, czy kolumny się zgadzają – w praktyce dość trudne.\n",
    "        # - alternatywa: wylosować z wielowymiarowego rozkładu hipergeometrycznego\n",
    "        #   \"zgodną\" tabelę. Poniżej sposób uproszczony (tzw. \"shaking columns\"):\n",
    "        \n",
    "        # Losujemy ciąg grand_total elementów do kolumn, a następnie układamy wierszami\n",
    "        # tak, by row_sums wypadły zgodnie. Jedna z podejść to tzw. \"multinomial approach\".\n",
    "        \n",
    "        # PRZYBLIŻENIE: Tasujemy wektor z etykietami kolumn, a następnie liczymy\n",
    "        #   ile wylądowało w wierszu i.\n",
    "        \n",
    "        # Tworzymy listę kolumn rozpisaną np. col_sums[0] razy \"kolumna0\", col_sums[1] razy \"kolumna1\", ...\n",
    "        col_list = []\n",
    "        for j, csum in enumerate(col_sums):\n",
    "            col_list.extend([j]*csum)\n",
    "        \n",
    "        # Mieszamy\n",
    "        np.random.shuffle(col_list)\n",
    "        \n",
    "        # Teraz rozkładamy to w wiersze wg row_sums:\n",
    "        random_table = np.zeros_like(table)\n",
    "        start = 0\n",
    "        for i, rsum in enumerate(row_sums):\n",
    "            # Wiersz i ma rsum elementów\n",
    "            row_columns = col_list[start:start+rsum]\n",
    "            start += rsum\n",
    "            # zliczamy ile wypadło do każdej kolumny:\n",
    "            for j in row_columns:\n",
    "                random_table[i, j] += 1\n",
    "        \n",
    "        # Liczymy pmf:\n",
    "        p_rand = hypergeom_pmf(random_table)\n",
    "        if p_rand <= p_obs:\n",
    "            count_le += 1\n",
    "    \n",
    "    p_value = count_le / n_iter\n",
    "    return p_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testy Freemana–Haltona (PYT_2) ===\n",
      "a) stanowisko kier. ~ wiek: p-value = 0.7847\n",
      "   Brak podstaw do odrzucenia H0 => zmienne niezależne\n",
      "\n",
      "b) stanowisko kier. ~ staż: p-value = 0.0001\n",
      "   Odrzucamy H0 => zmienne są zależne (istotne stat.)\n",
      "\n",
      "c) zadowolenie (PYT_2) ~ stanowisko kier.: p-value = 0.0442\n",
      "   Odrzucamy H0 => zmienne są zależne (istotne stat.)\n",
      "\n",
      "d) zadowolenie (PYT_2) ~ staż: p-value = 0.0109\n",
      "   Odrzucamy H0 => zmienne są zależne (istotne stat.)\n",
      "\n",
      "e) zadowolenie (PYT_2) ~ płeć: p-value = 0.4764\n",
      "   Brak podstaw do odrzucenia H0 => zmienne niezależne\n",
      "\n",
      "f) zadowolenie (PYT_2) ~ wiek: p-value = 0.3189\n",
      "   Brak podstaw do odrzucenia H0 => zmienne niezależne\n",
      "\n",
      "=== Testy Freemana–Haltona (CZY_ZADOW) ===\n",
      "c') CZY_ZADOW ~ stanowisko kier.: p-value = 0.8389\n",
      "   Brak podstaw do odrzucenia H0 => zmienne niezależne\n",
      "\n",
      "d') CZY_ZADOW ~ staż: p-value = 0.4078\n",
      "   Brak podstaw do odrzucenia H0 => zmienne niezależne\n",
      "\n",
      "e') CZY_ZADOW ~ płeć: p-value = 0.6599\n",
      "   Brak podstaw do odrzucenia H0 => zmienne niezależne\n",
      "\n",
      "f') CZY_ZADOW ~ wiek: p-value = 0.3284\n",
      "   Brak podstaw do odrzucenia H0 => zmienne niezależne\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df['CZY_ZADOW'] = df['PYT_2'].replace({\n",
    "    -2: 'niezadowolony',\n",
    "    -1: 'niezadowolony',\n",
    "     1: 'zadowolony',\n",
    "     2: 'zadowolony'\n",
    "})\n",
    "\n",
    "# 3. Lista par zmiennych do testowania oraz krótki opis hipotezy\n",
    "to_test = [\n",
    "    # (a)\n",
    "    ('CZY_KIER', 'WIEK_KAT', \"a) stanowisko kier. ~ wiek\"),\n",
    "    # (b)\n",
    "    ('CZY_KIER', 'STAŻ',     \"b) stanowisko kier. ~ staż\"),\n",
    "    # (c)\n",
    "    ('PYT_2',    'CZY_KIER', \"c) zadowolenie (PYT_2) ~ stanowisko kier.\"),\n",
    "    # (d)\n",
    "    ('PYT_2',    'STAŻ',     \"d) zadowolenie (PYT_2) ~ staż\"),\n",
    "    # (e)\n",
    "    ('PYT_2',    'PŁEĆ',     \"e) zadowolenie (PYT_2) ~ płeć\"),\n",
    "    # (f)\n",
    "    ('PYT_2',    'WIEK_KAT', \"f) zadowolenie (PYT_2) ~ wiek\"),\n",
    "]\n",
    "\n",
    "print(\"=== Testy Freemana–Haltona (PYT_2) ===\")\n",
    "for var_x, var_y, desc in to_test:\n",
    "    tab = pd.crosstab(df[var_x], df[var_y])\n",
    "    pval = fisher_freeman_halton(tab, method=\"montecarlo\", n_iter=50000)\n",
    "    print(f\"{desc}: p-value = {pval:.4f}\")\n",
    "    if pval < 0.05:\n",
    "        print(\"   Odrzucamy H0 => zmienne są zależne (istotne stat.)\\n\")\n",
    "    else:\n",
    "        print(\"   Brak podstaw do odrzucenia H0 => zmienne niezależne\\n\")\n",
    "\n",
    "# 4. Powtórzenie testów dla CZY_ZADOW zamiast PYT_2 w punktach c), d), e), f\n",
    "to_test_czy_zadow = [\n",
    "    ('CZY_ZADOW', 'CZY_KIER', \"c') CZY_ZADOW ~ stanowisko kier.\"),\n",
    "    ('CZY_ZADOW', 'STAŻ',     \"d') CZY_ZADOW ~ staż\"),\n",
    "    ('CZY_ZADOW', 'PŁEĆ',     \"e') CZY_ZADOW ~ płeć\"),\n",
    "    ('CZY_ZADOW', 'WIEK_KAT', \"f') CZY_ZADOW ~ wiek\"),\n",
    "]\n",
    "\n",
    "print(\"=== Testy Freemana–Haltona (CZY_ZADOW) ===\")\n",
    "for var_x, var_y, desc in to_test_czy_zadow:\n",
    "    tab = pd.crosstab(df[var_x], df[var_y])\n",
    "    pval = fisher_freeman_halton(tab, method=\"montecarlo\", n_iter=50000)\n",
    "    print(f\"{desc}: p-value = {pval:.4f}\")\n",
    "    if pval < 0.05:\n",
    "        print(\"   Odrzucamy H0 => zmienne są zależne (istotne stat.)\\n\")\n",
    "    else:\n",
    "        print(\"   Brak podstaw do odrzucenia H0 => zmienne niezależne\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
